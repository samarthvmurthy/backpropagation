# Simple Neural Network Implementation

This Python script implements a simple neural network with one hidden layer using the sigmoid activation function. The network is trained on the XOR problem as a demonstration of its capabilities.

## Project Structure

1. **`neural_network.py`:**
   - The main script containing the implementation of the simple neural network.

2. **`README.md`:**
   - The README file providing an overview of the project and instructions on how to run the neural network.

## Getting Started

Follow these steps to set up and run the simple neural network:

1. Clone the repository to your local machine:
   ```bash
   git clone https://github.com/your-username/simple-neural-network.git
   cd simple-neural-network
   ```

2. Run the neural network script:
   ```bash
   python neural_network.py
   ```

   The script will output the predicted values after training the neural network on the XOR problem.

## Neural Network Architecture

The neural network has the following architecture:
- Input layer with 2 neurons
- Hidden layer with 2 neurons
- Output layer with 1 neuron

The activation function used is the sigmoid function.

## Training

The neural network is trained on the XOR problem for 10,000 epochs with a learning rate of 0.1.

## Predictions

The script prints the predicted values after training the neural network.

## Contributing

Contributions are welcome! If you have suggestions, find issues, or want to enhance the neural network, please feel free to open issues or submit pull requests.

